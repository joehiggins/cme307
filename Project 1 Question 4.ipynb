{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import random\n",
    "from scipy import linalg\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent and Projection Method\n",
    "\n",
    "For a first order Steepest Descent method for the SNL problem, one of the main issues is ensuring that the semi-definite constraint is enforced at each iteration. In this project, we try 3 different approaches: \n",
    "\n",
    " * Eigenvalue decomposition, ensuring that none of the eigenvalues are negative.\n",
    " * LDL decomposition, ensuring that none of the pivots in D are negative.\n",
    " * Eigenvalue decomposition, keeping only the k largest positive eigenvalues.\n",
    "\n",
    "We find that the eigenvalue decomposition works consistently for ten sensors, four anchors, and two dimensions. For the LDL decomposition, we realized this approach is ill-suited to maintaining positive semi definitness. This is becase the LDL decomposition requires the matrix to be *positive definite* in the first place in order to run. This leads the algorithm to fail once the point falls out of the feasible region. For the approach using only k of the largest positive eigenvalues, we predictably succeed if k = n, as this simply becomes the first approach outlined. However, as soon as k < n, the algorithm never converges on the correct sensor locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_points(num, dim):\n",
    "    return np.matrix(4 * np.random.random((num, dim)) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sensors = 10\n",
    "num_anchors = 4\n",
    "dim = 2\n",
    "range_mult = 1\n",
    "\n",
    "anchors = generate_points(num_anchors, dim) * range_mult\n",
    "sensors = generate_points(num_sensors, dim)\n",
    "\n",
    "d_sa = list(map(lambda s: list(map(lambda a: np.linalg.norm(a - s), anchors)), sensors))\n",
    "\n",
    "d_ss = list(map(lambda s1: \n",
    "        list(map(lambda s2: np.linalg.norm(s1 - s2), sensors))\n",
    "    , sensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same as from Question 1.\n",
    "# Make first set of constraint matrices (look like identity)\n",
    "def enforce_id(dim, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(dim):\n",
    "        new_matrix = np.zeros((dim+num_sensors, dim+num_sensors))\n",
    "        new_matrix[i,i] = 1\n",
    "        matrices.append(new_matrix)\n",
    "        rhs.append(1)\n",
    "        \n",
    "    return (matrices, rhs)\n",
    "\n",
    "#Make second set of constraint matrices (symmetric holders) \n",
    "def enforce_id2(dim, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            new_matrix = np.identity(dim)\n",
    "            if(j > i):\n",
    "                new_matrix[i,j] = 1\n",
    "                new_matrix[j,i] = 1\n",
    "                big_matrix = np.zeros((dim+num_sensors, dim+num_sensors))\n",
    "                big_matrix[0:dim,0:dim] = new_matrix\n",
    "                matrices.append(big_matrix)\n",
    "                rhs.append(dim)\n",
    "                \n",
    "    return (matrices, rhs)\n",
    "\n",
    "\n",
    "#Make third set of constraint matrices (anchors to sensors)\n",
    "def sensor_constraints(dim, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    zero_vec_dim = np.zeros(dim)\n",
    "    for i in range(num_sensors):\n",
    "        for j in range(i+1, num_sensors):\n",
    "            zero_vec_num_s = np.zeros(num_sensors)\n",
    "            zero_vec_num_s[i] = 1\n",
    "            zero_vec_num_s[j] = -1\n",
    "            \n",
    "            new_vec = np.matrix(np.append(zero_vec_dim, zero_vec_num_s))\n",
    "            \n",
    "            new_matrix = np.dot(np.transpose(new_vec), new_vec)\n",
    "            \n",
    "            matrices.append(new_matrix)\n",
    "            rhs.append(d_ss[i][j]**2)\n",
    "\n",
    "    return (matrices, rhs)\n",
    "\n",
    "#Make fourth set of constraint matrices (sensors to sensors)\n",
    "def anchor_constraints(num_anchors, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(num_anchors):\n",
    "        for j in range(num_sensors):\n",
    "            zero_vec_num_s = np.zeros(num_sensors)\n",
    "            zero_vec_num_s[j] = -1\n",
    "\n",
    "            new_vec = np.append(np.array(anchors[i,:]), np.array(zero_vec_num_s))\n",
    "            new_vec = np.matrix(new_vec)\n",
    "            new_matrix = np.dot(np.transpose(new_vec), new_vec)\n",
    "            matrices.append(new_matrix)\n",
    "            rhs.append(d_sa[j][i]**2)\n",
    "\n",
    "    return (matrices, rhs)\n",
    "\n",
    "A = enforce_id(dim, num_sensors)\n",
    "B = enforce_id2(dim, num_sensors)\n",
    "C = sensor_constraints(dim, num_sensors)\n",
    "D = anchor_constraints(num_anchors, num_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_elem_product_noncvx(A,B):\n",
    "    return np.sum(np.multiply(A,B))\n",
    "\n",
    "def make_AX_less_b(X):\n",
    "    output = []\n",
    "    for id_constraint, rhs in zip(A[0], A[1]):\n",
    "        output.append(sum_elem_product_noncvx(id_constraint, X) - rhs)\n",
    "    for id_constraint2, rhs in zip(B[0], B[1]):\n",
    "        output.append(sum_elem_product_noncvx(id_constraint2, X) - rhs)\n",
    "    for sensor_constraint, rhs in zip(C[0], C[1]):\n",
    "        output.append(sum_elem_product_noncvx(sensor_constraint, X) - rhs)\n",
    "    for anchor_constraint, rhs in zip(D[0], D[1]):\n",
    "        output.append(sum_elem_product_noncvx(anchor_constraint, X) - rhs)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def scriptAt_y(y):\n",
    "    output = np.zeros((dim+num_sensors,dim+num_sensors)) #start sum of y_i*A_i\n",
    "    i = 0\n",
    "    for id_constraint, rhs in zip(A[0], A[1]):\n",
    "        output += np.multiply(id_constraint, y[i])\n",
    "        i = i + 1\n",
    "    for id_constraint2, rhs in zip(B[0], B[1]):\n",
    "        output += np.multiply(id_constraint2, y[i])\n",
    "        i = i + 1\n",
    "    for sensor_constraint, rhs in zip(C[0], C[1]):\n",
    "        output += np.multiply(sensor_constraint, y[i])\n",
    "        i = i + 1\n",
    "    for anchor_constraint, rhs in zip(D[0], D[1]):\n",
    "        output += np.multiply(anchor_constraint, y[i])\n",
    "        i = i + 1\n",
    "    return output\n",
    "\n",
    "def grad(X):\n",
    "    return scriptAt_y(make_AX_less_b(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_decomp_project(X_k1):\n",
    "    [eigenvalues, V] = np.linalg.eig(X_k1)\n",
    "    eigenvalues[eigenvalues < 0] = 0\n",
    "    Lambda = np.diag(eigenvalues)\n",
    "    return np.dot(np.dot(V, Lambda), np.transpose(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ldl_decomp_project(X_k1):\n",
    "    def ldl_decomp(A):\n",
    "        A = np.matrix(A)\n",
    "\n",
    "        S = np.diag(np.diag(A))\n",
    "        Sinv = np.diag(1/np.diag(A))\n",
    "        D = np.matrix(S.dot(S))\n",
    "        Lch = np.linalg.cholesky(A)\n",
    "        L = np.matrix(Lch.dot(Sinv))\n",
    "        return L, D\n",
    "    [L, D] = ldl_decomp(X_k1)\n",
    "    D[D < 0] = 0\n",
    "    D_psd = np.diag(D)\n",
    "    return np.dot(np.dot(L, D), np.transpose(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_proj(X):\n",
    "    [evalues, evectors] = scipy.linalg.eigh(X)\n",
    "    \n",
    "    idx = evalues.argsort()[::-1]   \n",
    "    evalues = evalues[idx]\n",
    "    evectors = evectors[:,idx]\n",
    "    \n",
    "    matrix = np.zeros(X.shape)\n",
    "    width = evalues.shape[0]\n",
    "    for i in range(9):\n",
    "        index = width - i - 1\n",
    "        if index >= 0 and evalues[index] > 0:\n",
    "            matrix += evalues[index] * np.outer(evectors[:, index], evectors[:, index])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Beta = 100\n",
    "def run_solver(method_name, projection_func):\n",
    "    thing = random.rand(dim + num_sensors, dim + num_sensors)\n",
    "    X_0 = np.dot(thing,thing.transpose())\n",
    "    X_k = X_0\n",
    "    k = 0\n",
    "    check = 1000\n",
    "    max_iter = 20000\n",
    "    \n",
    "    while check > 10**-8 and k < max_iter:\n",
    "        # Get next iterate from descent\n",
    "        X_k1 = X_k - (1/Beta) * grad(X_k)\n",
    "\n",
    "        # Project back into cone with eigen decomp\n",
    "        X_k1 = projection_func(X_k1)\n",
    "\n",
    "        #set up for next iteration\n",
    "        check = np.linalg.norm(X_k1 - X_k)  \n",
    "        X_k = X_k1\n",
    "\n",
    "        k = k+1\n",
    "    \n",
    "    print(\"Real sensors: \")\n",
    "    print(sensors)\n",
    "    print(\"Generated Sensors for method \" + method_name)\n",
    "    generated = np.transpose(X_k[0:dim, dim:dim+num_sensors])\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sensors: \n",
      "[[ 0.97591557 -1.90590207]\n",
      " [ 0.98879867 -0.61392471]\n",
      " [ 1.0582781  -1.50743397]\n",
      " [-1.61550811  0.52106587]\n",
      " [ 1.26337953  1.12418618]\n",
      " [ 1.10768273  1.44839876]\n",
      " [ 0.68032683  0.17353154]\n",
      " [ 1.07754533  1.49970902]\n",
      " [ 0.34527882 -0.13375661]\n",
      " [ 0.79291076 -1.78982923]]\n",
      "Generated Sensors for method Eigenvalue Decomposition\n",
      "[[ 0.9690596  -1.90176948]\n",
      " [ 0.98165871 -0.60973985]\n",
      " [ 1.05117266 -1.50322042]\n",
      " [-1.61638973  0.52271575]\n",
      " [ 1.25519359  1.12868242]\n",
      " [ 1.0997615   1.4527689 ]\n",
      " [ 0.67372273  0.17745107]\n",
      " [ 1.06967858  1.50405406]\n",
      " [ 0.33960666 -0.13018334]\n",
      " [ 0.78641769 -1.78584476]]\n"
     ]
    }
   ],
   "source": [
    "run_solver(\"Eigenvalue Decomposition\", eigen_decomp_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diverges with error because the matrix eventually becomes non positive-definite\n",
    "# run_solver(\"LDL Decomposition\", ldl_decomp_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sensors for method Top 6 Eigenavalues\n",
      "[[-0.08221924  0.18045344]\n",
      " [-0.02928192  0.03100771]\n",
      " [-0.40077771  0.20577432]\n",
      " [ 0.44870151 -0.11630888]\n",
      " [-0.06072766 -0.11967323]\n",
      " [-0.11978896 -0.04817487]\n",
      " [-0.07542121 -0.02036381]\n",
      " [ 0.00876687 -0.13781145]\n",
      " [ 0.07008961  0.02656377]\n",
      " [-0.09297427  0.12753467]]\n"
     ]
    }
   ],
   "source": [
    "run_solver(\"Top 6 Eigenavalues\", pca_proj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
