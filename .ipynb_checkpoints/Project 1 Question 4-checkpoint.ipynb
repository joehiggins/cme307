{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import random\n",
    "from scipy import linalg\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_points(num, dim):\n",
    "    return np.matrix(4 * np.random.random((num, dim)) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sensors = 10\n",
    "num_anchors = 4\n",
    "dim = 2\n",
    "range_mult = 1\n",
    "\n",
    "anchors = generate_points(num_anchors, dim) * range_mult\n",
    "sensors = generate_points(num_sensors, dim)\n",
    "\n",
    "d_sa = list(map(lambda s: list(map(lambda a: np.linalg.norm(a - s), anchors)), sensors))\n",
    "\n",
    "d_ss = list(map(lambda s1: \n",
    "        list(map(lambda s2: np.linalg.norm(s1 - s2), sensors))\n",
    "    , sensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same as from Question 1.\n",
    "# Make first set of constraint matrices (look like identity)\n",
    "def enforce_id(dim, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(dim):\n",
    "        new_matrix = np.zeros((dim+num_sensors, dim+num_sensors))\n",
    "        new_matrix[i,i] = 1\n",
    "        matrices.append(new_matrix)\n",
    "        rhs.append(1)\n",
    "        \n",
    "    return (matrices, rhs)\n",
    "\n",
    "#Make second set of constraint matrices (symmetric holders) \n",
    "def enforce_id2(dim, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            new_matrix = np.identity(dim)\n",
    "            if(j > i):\n",
    "                new_matrix[i,j] = 1\n",
    "                new_matrix[j,i] = 1\n",
    "                big_matrix = np.zeros((dim+num_sensors, dim+num_sensors))\n",
    "                big_matrix[0:dim,0:dim] = new_matrix\n",
    "                matrices.append(big_matrix)\n",
    "                rhs.append(dim)\n",
    "                \n",
    "    return (matrices, rhs)\n",
    "\n",
    "\n",
    "#Make third set of constraint matrices (anchors to sensors)\n",
    "def sensor_constraints(dim, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    zero_vec_dim = np.zeros(dim)\n",
    "    for i in range(num_sensors):\n",
    "        for j in range(i+1, num_sensors):\n",
    "            zero_vec_num_s = np.zeros(num_sensors)\n",
    "            zero_vec_num_s[i] = 1\n",
    "            zero_vec_num_s[j] = -1\n",
    "            \n",
    "            new_vec = np.matrix(np.append(zero_vec_dim, zero_vec_num_s))\n",
    "            \n",
    "            new_matrix = np.dot(np.transpose(new_vec), new_vec)\n",
    "            \n",
    "            matrices.append(new_matrix)\n",
    "            rhs.append(d_ss[i][j]**2)\n",
    "\n",
    "    return (matrices, rhs)\n",
    "\n",
    "#Make fourth set of constraint matrices (sensors to sensors)\n",
    "def anchor_constraints(num_anchors, num_sensors):\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(num_anchors):\n",
    "        for j in range(num_sensors):\n",
    "            zero_vec_num_s = np.zeros(num_sensors)\n",
    "            zero_vec_num_s[j] = -1\n",
    "\n",
    "            new_vec = np.append(np.array(anchors[i,:]), np.array(zero_vec_num_s))\n",
    "            new_vec = np.matrix(new_vec)\n",
    "            new_matrix = np.dot(np.transpose(new_vec), new_vec)\n",
    "            matrices.append(new_matrix)\n",
    "            rhs.append(d_sa[j][i]**2)\n",
    "\n",
    "    return (matrices, rhs)\n",
    "\n",
    "A = enforce_id(dim, num_sensors)\n",
    "B = enforce_id2(dim, num_sensors)\n",
    "C = sensor_constraints(dim, num_sensors)\n",
    "D = anchor_constraints(num_anchors, num_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_elem_product_noncvx(A,B):\n",
    "    return np.sum(np.multiply(A,B))\n",
    "\n",
    "def make_AX_less_b(X):\n",
    "    output = []\n",
    "    for id_constraint, rhs in zip(A[0], A[1]):\n",
    "        output.append(sum_elem_product_noncvx(id_constraint, X) - rhs)\n",
    "    for id_constraint2, rhs in zip(B[0], B[1]):\n",
    "        output.append(sum_elem_product_noncvx(id_constraint2, X) - rhs)\n",
    "    for sensor_constraint, rhs in zip(C[0], C[1]):\n",
    "        output.append(sum_elem_product_noncvx(sensor_constraint, X) - rhs)\n",
    "    for anchor_constraint, rhs in zip(D[0], D[1]):\n",
    "        output.append(sum_elem_product_noncvx(anchor_constraint, X) - rhs)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def scriptAt_y(y):\n",
    "    output = np.zeros((dim+num_sensors,dim+num_sensors)) #start sum of y_i*A_i\n",
    "    i = 0\n",
    "    for id_constraint, rhs in zip(A[0], A[1]):\n",
    "        output += np.multiply(id_constraint, y[i])\n",
    "        i = i + 1\n",
    "    for id_constraint2, rhs in zip(B[0], B[1]):\n",
    "        output += np.multiply(id_constraint2, y[i])\n",
    "        i = i + 1\n",
    "    for sensor_constraint, rhs in zip(C[0], C[1]):\n",
    "        output += np.multiply(sensor_constraint, y[i])\n",
    "        i = i + 1\n",
    "    for anchor_constraint, rhs in zip(D[0], D[1]):\n",
    "        output += np.multiply(anchor_constraint, y[i])\n",
    "        i = i + 1\n",
    "    return output\n",
    "\n",
    "def grad(X):\n",
    "    return scriptAt_y(make_AX_less_b(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_decomp_project(X_k1):\n",
    "    [eigenvalues, V] = np.linalg.eig(X_k1)\n",
    "    eigenvalues[eigenvalues < 0] = 0\n",
    "    Lambda = np.diag(eigenvalues)\n",
    "    return np.dot(np.dot(V, Lambda), np.transpose(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ldl_decomp_project(X_k1):\n",
    "    def ldl_decomp(A):\n",
    "        A = np.matrix(A)\n",
    "\n",
    "        S = np.diag(np.diag(A))\n",
    "        Sinv = np.diag(1/np.diag(A))\n",
    "        D = np.matrix(S.dot(S))\n",
    "        Lch = np.linalg.cholesky(A)\n",
    "        L = np.matrix(Lch.dot(Sinv))\n",
    "        return L, D\n",
    "    [L, D] = ldl_decomp(X_k1)\n",
    "    D[D < 0] = 0\n",
    "    D_psd = np.diag(D)\n",
    "    return np.dot(np.dot(L, D), np.transpose(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Beta = 100\n",
    "def run_solver(method_name, projection_func):\n",
    "    thing = random.rand(dim + num_sensors, dim + num_sensors)\n",
    "    X_0 = np.dot(thing,thing.transpose())\n",
    "    X_k = X_0\n",
    "    k = 0\n",
    "    check = 1000\n",
    "    max_iter = 20000\n",
    "    \n",
    "    while check > 10**-8 and k < max_iter:\n",
    "        # Get next iterate from descent\n",
    "        X_k1 = X_k - (1/Beta) * grad(X_k)\n",
    "\n",
    "        # Project back into cone with eigen decomp\n",
    "        X_k1 = projection_func(X_k1)\n",
    "\n",
    "        #set up for next iteration\n",
    "        check = np.linalg.norm(X_k1 - X_k)  \n",
    "        X_k = X_k1\n",
    "\n",
    "        if(k%1000 == 0):\n",
    "            print(k)\n",
    "        k = k+1\n",
    "    \n",
    "    print(\"Real sensors: \")\n",
    "    print(sensors)\n",
    "    print(\"Generated Sensors for method \" + method_name)\n",
    "    generated = np.transpose(X_k[0:dim, dim:dim+num_sensors])\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "run_solver(\"Eigenvalue Decomposition\", eigen_decomp_project)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
