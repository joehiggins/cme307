{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group: Austin Wang, Joe Higgins, Lawrence Moore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import cvxpy as cvx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Average Performance of SOCP, SDP, and NLLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used for generating random anchors and sensors whose coordinates are in [-2,2]\n",
    "def generate_points(num, dim):\n",
    "    return np.matrix(4 * np.random.random((num, dim)) - 2)\n",
    "\n",
    "# For generating the sensor-sensor distances and sensor-anchor distances\n",
    "def generate_ss_distances(sensors):\n",
    "    return list(map(lambda s1: \n",
    "                list(map(lambda s2: np.linalg.norm(s1 - s2), sensors))\n",
    "            , sensors))\n",
    "\n",
    "def generate_sa_distances(sensors, anchors):\n",
    "    return list(map(lambda s: \n",
    "                list(map(lambda a: np.linalg.norm(a - s), anchors))\n",
    "            , sensors))\n",
    "\n",
    "# For defining the the matrix-matrix dot product\n",
    "def sum_elem_product(A,B):\n",
    "    return cvx.sum_entries(cvx.mul_elemwise(A, B))\n",
    "\n",
    "# For calculating the number of sensors that are correctly located\n",
    "def sensor_acc(x, true_sensors):\n",
    "    num_correct = 0\n",
    "    for i in range(true_sensors.shape[0]):\n",
    "        if abs(np.linalg.norm(x[i,:]-true_sensors[i,:])) <= 10**-2:\n",
    "            num_correct += 1\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDP Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make first set of constraint matrices (look like identity)\n",
    "def enforce_id(sensors):\n",
    "    dim = np.shape(sensors)[1]\n",
    "    num_sensors = np.shape(sensors)[0]\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(dim):\n",
    "        new_matrix = np.zeros((dim+num_sensors, dim+num_sensors))\n",
    "        new_matrix[i,i] = 1\n",
    "        matrices.append(new_matrix)\n",
    "        rhs.append(1)\n",
    "        \n",
    "    return (matrices, rhs)\n",
    "\n",
    "#Make second set of constraint matrices (symmetric holders) \n",
    "def enforce_id2(sensors):\n",
    "    dim = np.shape(sensors)[1]\n",
    "    num_sensors = np.shape(sensors)[0]\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            new_matrix = np.identity(dim)\n",
    "            if(j > i):\n",
    "                new_matrix[i,j] = 1\n",
    "                new_matrix[j,i] = 1\n",
    "                big_matrix = np.zeros((dim+num_sensors, dim+num_sensors))\n",
    "                big_matrix[0:dim,0:dim] = new_matrix\n",
    "                matrices.append(big_matrix)\n",
    "                rhs.append(dim)\n",
    "                \n",
    "    return (matrices, rhs)\n",
    "\n",
    "\n",
    "#Make third set of constraint matrices (anchors to sensors)\n",
    "def sensor_constraints(sensors):\n",
    "    dim = np.shape(sensors)[1]\n",
    "    num_sensors = np.shape(sensors)[0]\n",
    "    d_ss = generate_ss_distances(sensors)\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    zero_vec_dim = np.zeros(dim)\n",
    "    for i in range(num_sensors):\n",
    "        for j in range(i+1, num_sensors):\n",
    "            zero_vec_num_s = np.zeros(num_sensors)\n",
    "            zero_vec_num_s[i] = 1\n",
    "            zero_vec_num_s[j] = -1\n",
    "            \n",
    "            new_vec = np.matrix(np.append(zero_vec_dim, zero_vec_num_s))\n",
    "            \n",
    "            new_matrix = np.dot(np.transpose(new_vec), new_vec)\n",
    "            \n",
    "            matrices.append(new_matrix)\n",
    "            rhs.append(d_ss[i][j]**2)\n",
    "\n",
    "    return (matrices, rhs)\n",
    "\n",
    "#Make fourth set of constraint matrices (sensors to sensors)\n",
    "def anchor_constraints(sensors, anchors):\n",
    "    num_sensors = np.shape(sensors)[0]\n",
    "    num_anchors = np.shape(anchors)[0]\n",
    "    d_sa = generate_sa_distances(sensors, anchors)\n",
    "    matrices = []\n",
    "    rhs = []\n",
    "    for i in range(num_anchors):\n",
    "        for j in range(num_sensors):\n",
    "            zero_vec_num_s = np.zeros(num_sensors)\n",
    "            zero_vec_num_s[j] = -1\n",
    "\n",
    "            new_vec = np.append(np.array(anchors[i,:]), np.array(zero_vec_num_s))\n",
    "            new_vec = np.matrix(new_vec)\n",
    "            new_matrix = np.dot(np.transpose(new_vec), new_vec)\n",
    "            matrices.append(new_matrix)\n",
    "            rhs.append(d_sa[j][i]**2)\n",
    "\n",
    "    return (matrices, rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLLS Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient of objective\n",
    "def grad(sensors, anchors, sens2sens_dist, sens2anc_dist):\n",
    "    dim = sensors.shape[1]\n",
    "    sensor_distance_sum = np.zeros((1,dim))\n",
    "    anchor_distance_sum = np.zeros((1,dim))\n",
    "    gradient = np.zeros(sensors.shape)\n",
    "\n",
    "    for i, sensor_i in enumerate(sensors):\n",
    "        for j, sensor_j in enumerate(sensors):\n",
    "            if(i != j):\n",
    "                sensor_distance_sum += (np.linalg.norm(sensor_i - sensor_j)**2 - \\\n",
    "                                        np.linalg.norm(sens2sens_dist[i][j])**2) * \\\n",
    "                                       (sensor_i - sensor_j)\n",
    "\n",
    "        for k, anchor_k in enumerate(anchors):\n",
    "            anchor_distance_sum += (np.linalg.norm(anchor_k - sensor_i)**2 - \\\n",
    "                                    np.linalg.norm(sens2anc_dist[i][k])**2) * \\\n",
    "                                   (sensor_i - anchor_k)\n",
    "\n",
    "        gradient[i,:] = 8*sensor_distance_sum + 4*anchor_distance_sum\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Method Run Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the number of correctly located sensors for SOCP\n",
    "def run_socp(sensors, anchors):\n",
    "    d_ss = generate_ss_distances(sensors)\n",
    "    d_sa = generate_sa_distances(sensors, anchors)\n",
    "    \n",
    "    dim = sensors.shape[1]\n",
    "    num_sensors = 10\n",
    "    num_anchors = anchors.shape[0]\n",
    "    x = cvx.Variable(num_sensors, dim)\n",
    "    objective = cvx.Minimize(0)\n",
    "    \n",
    "    constraints  = []\n",
    "    for i in range(num_sensors):\n",
    "        x_i = x[i, :]\n",
    "        for j in range(num_anchors):\n",
    "            constraints.append(cvx.norm(x_i - anchors[j]) <= d_sa[i][j])\n",
    "        for j in range(num_sensors):\n",
    "            if i < j:\n",
    "                constraints.append(cvx.norm(x_i - sensors[j]) <= d_ss[i][j])\n",
    "\n",
    "    prob = cvx.Problem(objective, constraints)\n",
    "    result = prob.solve(solver = 'MOSEK')\n",
    "    return sensor_acc(x.value, sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the number of correctly located sensors for SDP\n",
    "def run_sdp(sensors, anchors):    \n",
    "    \n",
    "    # Make constraints\n",
    "    A = enforce_id(sensors)\n",
    "    B = enforce_id2(sensors)\n",
    "    C = sensor_constraints(sensors)\n",
    "    D = anchor_constraints(sensors, anchors)\n",
    "    \n",
    "    # Parameters\n",
    "    dim = sensors.shape[1]\n",
    "    num_sensors = 10\n",
    "    num_anchors = anchors.shape[0]\n",
    "    Z = cvx.Semidef(num_sensors + dim)\n",
    "    \n",
    "    constraints = []\n",
    "    for id_constraint, rhs in zip(A[0], A[1]):\n",
    "        constraints.append(sum_elem_product(id_constraint, Z) == rhs)\n",
    "    for id_constraint2, rhs in zip(B[0], B[1]):\n",
    "        constraints.append(sum_elem_product(id_constraint2, Z) == rhs)\n",
    "    for sensor_constraint, rhs in zip(C[0], C[1]):\n",
    "        constraints.append(sum_elem_product(sensor_constraint, Z) == rhs)\n",
    "    for anchor_constraint, rhs in zip(D[0], D[1]):\n",
    "        constraints.append(sum_elem_product(anchor_constraint, Z) == rhs)\n",
    "        \n",
    "    objective = cvx.Minimize(0)\n",
    "    prob = cvx.Problem(objective, constraints)\n",
    "    result = prob.solve(solver = 'MOSEK')\n",
    "    sol = np.transpose(Z[0:dim, dim:dim+num_sensors].value)\n",
    "    \n",
    "    return sensor_acc(sol, sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_nlls(sensors, anchors):\n",
    "    check = 1000\n",
    "    max_iter = 10000\n",
    "    k = 0\n",
    "\n",
    "    # Parameters and initial data\n",
    "    dim = sensors.shape[1]\n",
    "    num_sensors = 10\n",
    "    num_anchors = anchors.shape[0]\n",
    "    d_ss = generate_ss_distances(sensors)\n",
    "    d_sa = generate_sa_distances(sensors, anchors)\n",
    "    \n",
    "    # Initial sensors guess\n",
    "    \n",
    "    # RESULTS QUITE SENSITIVE TO INITIAL GUESS AS WELL\n",
    "    sensors_0 = np.zeros(sensors.shape)\n",
    "    sensors_k = sensors_0\n",
    "\n",
    "\n",
    "    # Iteration\n",
    "    alpha = .0001 # Result quite sensitive to alpha; chose from empirical evidence\n",
    "    while check > 10**-6 and k < max_iter:\n",
    "        sensors_k1 = sensors_k - alpha * grad(sensors_k, anchors, d_ss, d_sa)\n",
    "        check = np.linalg.norm(sensors_k1 - sensors_k)\n",
    "        sensors_k = sensors_k1\n",
    "        k = k+1\n",
    "    return sensor_acc(sensors_k1, sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test (should be removed in final notebook)\n",
    "#sensors = generate_points(10,3)\n",
    "#anchors = generate_points(4,3)\n",
    "#run_nlls(sensors,anchors)\n",
    "\n",
    "# NOTE: NEED TO TRY DIFFERENT ALPHAS AND INITIAL SENSOR GUESSES TO MAKE\n",
    "# CONVERGE TO PROPER SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that takes in a given dimension dim in [1,2,3] and outputs\n",
    "# a tuple of 3 lists of lists. Each of these three outer lists corresponds\n",
    "# to the data for SOCP, SDP, and Nonlinear Least Squares. The inner lists each\n",
    "# correspond to the number of anchors in [2,3,4]. The values in each of these inner\n",
    "# lists are the average number of sensors out of the 10 that were located correctly\n",
    "# out of 50 trials\n",
    "def execute_solvers(dim):\n",
    "    SOCP_vals = []\n",
    "    SDP_vals = []\n",
    "    NLLS_vals = []\n",
    "    for anc_i in num_anchors:\n",
    "        socp_sum = 0\n",
    "        sdp_sum = 0\n",
    "        nlls_sum = 0\n",
    "        for j in range(50):\n",
    "            # Initialize data for a given trial\n",
    "            sensors = generate_points(10, dim)\n",
    "            anchors = generate_points(anc_i, dim)\n",
    "            \n",
    "            socp_sum += run_socp(sensors, anchors)\n",
    "            sdp_sum += run_sdp(sensors, anchors)\n",
    "            nlls_sum += run_nlls(sensors, anchors)\n",
    "        SOCP_vals.append(socp_sum/50)\n",
    "        SDP_vals.append(sdp_sum/50)\n",
    "        NLLS_vals.append(nlls_sum/50)\n",
    "        print('Finished One Anchor Iteration')\n",
    "\n",
    "    return (SOCP_vals, SDP_vals, NLLS_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anchors = [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished One Anchor Iteration\n",
      "Finished One Anchor Iteration\n",
      "Finished One Anchor Iteration\n"
     ]
    }
   ],
   "source": [
    "dim1 = execute_solvers(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim2 = execute_solvers(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim3 = execute_solvers(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
